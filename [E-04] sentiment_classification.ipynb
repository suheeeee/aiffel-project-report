{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "synthetic-joshua",
   "metadata": {},
   "source": [
    "# 네이버 영화리뷰 감성분석\n",
    "\n",
    "---\n",
    "\n",
    "한국어로 된 네이버 영화 리뷰 텍스트를 이용하여 감성분석을 수행하고 이를 평가해본다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adequate-lighter",
   "metadata": {},
   "source": [
    "## 데이터 준비와 확인\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "south-restaurant",
   "metadata": {},
   "source": [
    "- 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "royal-nomination",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>149995</th>\n",
       "      <td>6222902</td>\n",
       "      <td>인간이 문제지.. 소는 뭔죄인가..</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149996</th>\n",
       "      <td>8549745</td>\n",
       "      <td>평점이 너무 낮아서...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149997</th>\n",
       "      <td>9311800</td>\n",
       "      <td>이게 뭐요? 한국인은 거들먹거리고 필리핀 혼혈은 착하다?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149998</th>\n",
       "      <td>2376369</td>\n",
       "      <td>청춘 영화의 최고봉.방황과 우울했던 날들의 자화상</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149999</th>\n",
       "      <td>9619869</td>\n",
       "      <td>한국 영화 최초로 수간하는 내용이 담긴 영화</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                         document  label\n",
       "149995  6222902              인간이 문제지.. 소는 뭔죄인가..      0\n",
       "149996  8549745                    평점이 너무 낮아서...      1\n",
       "149997  9311800  이게 뭐요? 한국인은 거들먹거리고 필리핀 혼혈은 착하다?      0\n",
       "149998  2376369      청춘 영화의 최고봉.방황과 우울했던 날들의 자화상      1\n",
       "149999  9619869         한국 영화 최초로 수간하는 내용이 담긴 영화      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data = pd.read_table(workspace_path + '/ratings_train.txt')\n",
    "test_data  = pd.read_table(workspace_path + '/ratings_test.txt')\n",
    "display(train_data.head(5))\n",
    "display(train_data.tail(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sacred-butter",
   "metadata": {},
   "source": [
    "## 데이터로더 구성\n",
    "---\n",
    "\n",
    "데이터로더 `data_loader`는 다음 기능을 수행해야 한다.\n",
    "- 데이터의 중복 제거\n",
    "- NaN 결측치 제거\n",
    "- 한국어 토크나이저로 토큰화\n",
    "- 불용어(Stopwords) 제거\n",
    "- 사전`word_to_index` 구성\n",
    "- 텍스트 스트링을 사전 인덱스 스트링으로 변환\n",
    "- `X_train`, `y_train`, `X_test`, `y_test`, `word_to_index` 리턴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "formed-allen",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test, word_to_index = load_data(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "improving-palestine",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_to_index.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "foreign-button",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "index_to_word = {index:word for word, index in word_to_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "heated-avatar",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'. .. 포스터 보고 초딩 영화 줄 . ... 오버 연기 조차 가볍 지 않 구나'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_decoded_sentence(X_train[1], index_to_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cheap-assistant",
   "metadata": {},
   "source": [
    "## 모델구성을 위한 데이터 분석 및 가공\n",
    "---\n",
    "- 데이터셋 내 문장 길이 분포"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "electric-absence",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장길이 평균 :  15.969376315021577\n",
      "문장길이 최대 :  116\n",
      "문장길이 표준편차 :  12.843535456326455\n"
     ]
    }
   ],
   "source": [
    "total_data_text = list(X_train) + list(X_test)\n",
    "\n",
    "# 텍스트데이터 문장길이의 리스트를 생성한 후\n",
    "num_tokens = [len(tokens) for tokens in total_data_text]\n",
    "num_tokens = np.array(num_tokens)\n",
    "\n",
    "# 문장길이의 평균값, 최대값, 표준편차를 계산해 본다. \n",
    "print('문장길이 평균 : ', np.mean(num_tokens))\n",
    "print('문장길이 최대 : ', np.max(num_tokens))\n",
    "print('문장길이 표준편차 : ', np.std(num_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "several-habitat",
   "metadata": {},
   "source": [
    "- 적절한 최대 문장 길이 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "herbal-notification",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pad_sequences maxlen :  41\n",
      "전체 문장의 0.9342988343341575%가 maxlen 설정값 이내에 포함됩니다. \n"
     ]
    }
   ],
   "source": [
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "# max_tokens = 100\n",
    "maxlen = int(max_tokens)\n",
    "print('pad_sequences maxlen : ', maxlen)\n",
    "print('전체 문장의 {}%가 maxlen 설정값 이내에 포함됩니다. '.format(np.sum(num_tokens < max_tokens) / len(num_tokens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "express-karaoke",
   "metadata": {},
   "source": [
    "- keras.preprocessing.sequence.pad_sequences 을 활용한 패딩 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "stone-plant",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((146182, 41), (49157, 41))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = add_padding(X_train, 'pre', maxlen)\n",
    "X_test = add_padding(X_test, 'pre', maxlen)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gross-corner",
   "metadata": {},
   "source": [
    "## 모델구성 및 validation set 구성\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "under-iraqi",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models = []\n",
    "model_names = ['RNN', '1_D_CNN', '1_D_1_Layer_CNN']\n",
    "vocab_size = len(word_to_index.keys())\n",
    "word_vector_dim = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excellent-national",
   "metadata": {},
   "source": [
    "- RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "structured-garlic",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/aiffel-dj1/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/aiffel-dj1/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 16)          160000    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 8)                 800       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 160,881\n",
      "Trainable params: 160,881\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "models.append(get_rnn_model(vocab_size, word_vector_dim, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worthy-sound",
   "metadata": {},
   "source": [
    "- 1-D Convolution Neural Network(1-D CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "touched-montana",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 16)          160000    \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, None, 16)          1808      \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, None, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, None, 16)          1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 163,761\n",
      "Trainable params: 163,761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "models.append(get_one_d_cnn_model(vocab_size, word_vector_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greek-generic",
   "metadata": {},
   "source": [
    "- 1-D Convolution Neural Network(1-D CNN) with one layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "sustainable-implementation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 16)          160000    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 160,145\n",
      "Trainable params: 160,145\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "models.append(get_one_d_one_l_cnn_model(vocab_size, word_vector_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "union-willow",
   "metadata": {},
   "source": [
    "## 모델 훈련 개시\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "altered-notion",
   "metadata": {},
   "source": [
    "- validation set 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "guilty-unknown",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(136182, 41)\n",
      "(136182,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=10000, random_state=42)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exempt-update",
   "metadata": {},
   "source": [
    "- model 학습 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "drawn-spelling",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "sustainable-occasions",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start train RNN ============================================== \n",
      "WARNING:tensorflow:From /home/aiffel-dj1/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 136182 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "136182/136182 - 8s - loss: 0.4936 - acc: 0.7766 - val_loss: 0.3615 - val_acc: 0.8498\n",
      "Epoch 2/20\n",
      "136182/136182 - 7s - loss: 0.3400 - acc: 0.8564 - val_loss: 0.3482 - val_acc: 0.8471\n",
      "Epoch 3/20\n",
      "136182/136182 - 7s - loss: 0.3173 - acc: 0.8670 - val_loss: 0.3403 - val_acc: 0.8552\n",
      "Epoch 4/20\n",
      "136182/136182 - 8s - loss: 0.3052 - acc: 0.8724 - val_loss: 0.3394 - val_acc: 0.8521\n",
      "Epoch 5/20\n",
      "136182/136182 - 7s - loss: 0.2941 - acc: 0.8768 - val_loss: 0.3379 - val_acc: 0.8515\n",
      "Epoch 6/20\n",
      "136182/136182 - 7s - loss: 0.2836 - acc: 0.8812 - val_loss: 0.3411 - val_acc: 0.8496\n",
      "Epoch 7/20\n",
      "136182/136182 - 7s - loss: 0.2746 - acc: 0.8848 - val_loss: 0.3428 - val_acc: 0.8506\n",
      "Epoch 8/20\n",
      "136182/136182 - 7s - loss: 0.2631 - acc: 0.8898 - val_loss: 0.3494 - val_acc: 0.8505\n",
      "Epoch 9/20\n",
      "136182/136182 - 7s - loss: 0.2529 - acc: 0.8943 - val_loss: 0.3524 - val_acc: 0.8539\n",
      "Epoch 00009: early stopping\n",
      "train completed ============================================== \n",
      "start train 1_D_CNN ============================================== \n",
      "Train on 136182 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "136182/136182 - 2s - loss: 0.4774 - acc: 0.7703 - val_loss: 0.3528 - val_acc: 0.8460\n",
      "Epoch 2/20\n",
      "136182/136182 - 2s - loss: 0.3273 - acc: 0.8603 - val_loss: 0.3365 - val_acc: 0.8532\n",
      "Epoch 3/20\n",
      "136182/136182 - 2s - loss: 0.2964 - acc: 0.8765 - val_loss: 0.3331 - val_acc: 0.8541\n",
      "Epoch 4/20\n",
      "136182/136182 - 2s - loss: 0.2712 - acc: 0.8881 - val_loss: 0.3410 - val_acc: 0.8538\n",
      "Epoch 5/20\n",
      "136182/136182 - 2s - loss: 0.2433 - acc: 0.9026 - val_loss: 0.3487 - val_acc: 0.8539\n",
      "Epoch 6/20\n",
      "136182/136182 - 2s - loss: 0.2131 - acc: 0.9179 - val_loss: 0.3654 - val_acc: 0.8534\n",
      "Epoch 7/20\n",
      "136182/136182 - 2s - loss: 0.1818 - acc: 0.9333 - val_loss: 0.3887 - val_acc: 0.8510\n",
      "Epoch 00007: early stopping\n",
      "train completed ============================================== \n",
      "start train 1_D_1_Layer_CNN ============================================== \n",
      "Train on 136182 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "136182/136182 - 1s - loss: 0.6282 - acc: 0.6784 - val_loss: 0.5000 - val_acc: 0.8141\n",
      "Epoch 2/20\n",
      "136182/136182 - 1s - loss: 0.4057 - acc: 0.8372 - val_loss: 0.3665 - val_acc: 0.8443\n",
      "Epoch 3/20\n",
      "136182/136182 - 1s - loss: 0.3319 - acc: 0.8607 - val_loss: 0.3507 - val_acc: 0.8470\n",
      "Epoch 4/20\n",
      "136182/136182 - 1s - loss: 0.3021 - acc: 0.8741 - val_loss: 0.3495 - val_acc: 0.8482\n",
      "Epoch 5/20\n",
      "136182/136182 - 1s - loss: 0.2824 - acc: 0.8839 - val_loss: 0.3545 - val_acc: 0.8492\n",
      "Epoch 6/20\n",
      "136182/136182 - 1s - loss: 0.2667 - acc: 0.8915 - val_loss: 0.3613 - val_acc: 0.8480\n",
      "Epoch 7/20\n",
      "136182/136182 - 1s - loss: 0.2536 - acc: 0.8976 - val_loss: 0.3687 - val_acc: 0.8471\n",
      "Epoch 8/20\n",
      "136182/136182 - 1s - loss: 0.2421 - acc: 0.9031 - val_loss: 0.3796 - val_acc: 0.8455\n",
      "Epoch 00008: early stopping\n",
      "train completed ============================================== \n"
     ]
    }
   ],
   "source": [
    "histories = [train(models[i], model_names[i], X_train, y_train, X_val, y_val, epochs) \n",
    "             for i in range(len(models))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bulgarian-wichita",
   "metadata": {},
   "source": [
    "- 테스트셋으로 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "special-giving",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49157/49157 - 6s - loss: 0.3640 - acc: 0.8479\n",
      "49157/49157 - 1s - loss: 0.3990 - acc: 0.8453\n",
      "49157/49157 - 1s - loss: 0.3896 - acc: 0.8405\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RNN</th>\n",
       "      <td>0.363994</td>\n",
       "      <td>0.847875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_D_CNN</th>\n",
       "      <td>0.398989</td>\n",
       "      <td>0.845251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_D_1_Layer_CNN</th>\n",
       "      <td>0.389630</td>\n",
       "      <td>0.840491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     loss  accuracy\n",
       "RNN              0.363994  0.847875\n",
       "1_D_CNN          0.398989  0.845251\n",
       "1_D_1_Layer_CNN  0.389630  0.840491"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_res = [ models[i].evaluate(X_test,  y_test, verbose=2) for i in range(len(models)) ]\n",
    "df = pd.DataFrame(evaluation_res, index=model_names, columns=['loss', 'accuracy'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "transsexual-charity",
   "metadata": {},
   "source": [
    "테스트 결과 구상한 세가지 모델 중 RNN이 가장 성능이 좋았다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serious-blade",
   "metadata": {},
   "source": [
    "## Loss, Accuracy 그래프 시각화\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "addressed-california",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel-dj1/anaconda3/envs/aiffel/lib/python3.7/site-packages/ipykernel_launcher.py:12: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_history_plot(histories, model_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "departmental-insertion",
   "metadata": {},
   "source": [
    "## 학습된 Embedding 레이어 분석\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comic-creek",
   "metadata": {},
   "source": [
    "- 학습한 Embedding 파라미터를 txt 파일로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "forty-gauge",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.02435059, -0.07407113,  0.00871195, ..., -0.01922066,\n",
       "         0.02684289, -0.01014234],\n",
       "       [-0.02285335, -0.03341222, -0.02001619, ...,  0.01601448,\n",
       "         0.03994607, -0.03269925],\n",
       "       [-0.02863228,  0.01680109, -0.10421544, ..., -0.05001776,\n",
       "         0.03328235,  0.04511382],\n",
       "       ...,\n",
       "       [-0.140026  , -0.15502006, -0.09372608, ...,  0.1623353 ,\n",
       "         0.04926397,  0.15554827],\n",
       "       [-0.2259723 , -0.27662897, -0.20075093, ...,  0.19210947,\n",
       "        -0.05011493,  0.19194591],\n",
       "       [-0.00666549, -0.05850453, -0.01976708, ..., -0.04978821,\n",
       "        -0.01857595, -0.03466008]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models[0].get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "recreational-vinyl",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "save_embedding_layer(models, model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contemporary-helmet",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!ls ./word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alike-championship",
   "metadata": {},
   "source": [
    "- 저장한 Embedding 파라미터를 읽어 word vector로 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "wrong-sampling",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
    "\n",
    "base_path = workspace_path + '/data/suheeeee/'\n",
    "word_vectors = [Word2VecKeyedVectors.load_word2vec_format(base_path + key + '.txt', binary=False)\n",
    "                for key in model_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "future-italian",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>재미</th>\n",
       "      <td>너무</td>\n",
       "      <td>매우</td>\n",
       "      <td>심혜진</td>\n",
       "      <td>어이없이</td>\n",
       "      <td>거려서</td>\n",
       "      <td>다치</td>\n",
       "      <td>이렇게</td>\n",
       "      <td>완</td>\n",
       "      <td>넘</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>슬픔</th>\n",
       "      <td>ㅊ</td>\n",
       "      <td>공존</td>\n",
       "      <td>재발견</td>\n",
       "      <td>봣</td>\n",
       "      <td>메인</td>\n",
       "      <td>구입</td>\n",
       "      <td>틈</td>\n",
       "      <td>무서워서</td>\n",
       "      <td>안다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>아깝</th>\n",
       "      <td>고대로</td>\n",
       "      <td>아까워</td>\n",
       "      <td>탐험</td>\n",
       "      <td>랍시고</td>\n",
       "      <td>모모</td>\n",
       "      <td>당첨</td>\n",
       "      <td>사이트</td>\n",
       "      <td>와요</td>\n",
       "      <td>멀미</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>명작</th>\n",
       "      <td>곁</td>\n",
       "      <td>명연기</td>\n",
       "      <td>개꿀</td>\n",
       "      <td>A</td>\n",
       "      <td>열린</td>\n",
       "      <td>조아</td>\n",
       "      <td>감탄</td>\n",
       "      <td>~~^^</td>\n",
       "      <td>완벽</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>별로</th>\n",
       "      <td>포기</td>\n",
       "      <td>어설퍼</td>\n",
       "      <td>실망</td>\n",
       "      <td>오만</td>\n",
       "      <td>어리석</td>\n",
       "      <td>아까웠</td>\n",
       "      <td>낮추</td>\n",
       "      <td>재미없</td>\n",
       "      <td>다라마</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>유치</th>\n",
       "      <td>대충</td>\n",
       "      <td>방어</td>\n",
       "      <td>난감</td>\n",
       "      <td>본다고</td>\n",
       "      <td>화내</td>\n",
       "      <td>구리</td>\n",
       "      <td>파탄</td>\n",
       "      <td>실망</td>\n",
       "      <td>기대치</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>답답</th>\n",
       "      <td>OOO</td>\n",
       "      <td>악몽</td>\n",
       "      <td>시시</td>\n",
       "      <td>포기</td>\n",
       "      <td>내려</td>\n",
       "      <td>치중</td>\n",
       "      <td>무한도전</td>\n",
       "      <td>제한</td>\n",
       "      <td>배달</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      1    2    3     4    5    6     7     8    9\n",
       "재미   너무   매우  심혜진  어이없이  거려서   다치   이렇게     완    넘\n",
       "슬픔    ㅊ   공존  재발견     봣   메인   구입     틈  무서워서   안다\n",
       "아깝  고대로  아까워   탐험   랍시고   모모   당첨   사이트    와요   멀미\n",
       "명작    곁  명연기   개꿀     A   열린   조아    감탄  ~~^^   완벽\n",
       "별로   포기  어설퍼   실망    오만  어리석  아까웠    낮추   재미없  다라마\n",
       "유치   대충   방어   난감   본다고   화내   구리    파탄    실망  기대치\n",
       "답답  OOO   악몽   시시    포기   내려   치중  무한도전    제한   배달"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1_D_CNN\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>재미</th>\n",
       "      <td>여지껏</td>\n",
       "      <td>강동원</td>\n",
       "      <td>열라</td>\n",
       "      <td>도록</td>\n",
       "      <td>흥미</td>\n",
       "      <td>나옴</td>\n",
       "      <td>이정현</td>\n",
       "      <td>매우</td>\n",
       "      <td>그래서</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>슬픔</th>\n",
       "      <td>구입</td>\n",
       "      <td>김새론</td>\n",
       "      <td>탕웨이</td>\n",
       "      <td>낙원</td>\n",
       "      <td>깜찍</td>\n",
       "      <td>과자</td>\n",
       "      <td>어짜피</td>\n",
       "      <td>클로이</td>\n",
       "      <td>마음껏</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>아깝</th>\n",
       "      <td>재탕</td>\n",
       "      <td>개판</td>\n",
       "      <td>다이애나</td>\n",
       "      <td>끊</td>\n",
       "      <td>박정희</td>\n",
       "      <td>약했</td>\n",
       "      <td>발단</td>\n",
       "      <td>에서부터</td>\n",
       "      <td>써도</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>명작</th>\n",
       "      <td>로라</td>\n",
       "      <td>진진</td>\n",
       "      <td>싯</td>\n",
       "      <td>모건</td>\n",
       "      <td>드라마틱</td>\n",
       "      <td>쵝오</td>\n",
       "      <td>재밌</td>\n",
       "      <td>완벽</td>\n",
       "      <td>월요일</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>별로</th>\n",
       "      <td>다이</td>\n",
       "      <td>더냐</td>\n",
       "      <td>동거</td>\n",
       "      <td>방어</td>\n",
       "      <td>퇴화</td>\n",
       "      <td>당혹</td>\n",
       "      <td>어설프</td>\n",
       "      <td>횡설수설</td>\n",
       "      <td>밥맛</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>유치</th>\n",
       "      <td>재주</td>\n",
       "      <td>단조</td>\n",
       "      <td>나열</td>\n",
       "      <td>무미건조</td>\n",
       "      <td>빤</td>\n",
       "      <td>걸렸</td>\n",
       "      <td>망</td>\n",
       "      <td>나사</td>\n",
       "      <td>근거</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>답답</th>\n",
       "      <td>온갖</td>\n",
       "      <td>ㅓ</td>\n",
       "      <td>달려가</td>\n",
       "      <td>아휴</td>\n",
       "      <td>내려</td>\n",
       "      <td>강조</td>\n",
       "      <td>모니터</td>\n",
       "      <td>봐온</td>\n",
       "      <td>밥맛</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      1    2     3     4     5   6    7     8    9\n",
       "재미  여지껏  강동원    열라    도록    흥미  나옴  이정현    매우  그래서\n",
       "슬픔   구입  김새론   탕웨이    낙원    깜찍  과자  어짜피   클로이  마음껏\n",
       "아깝   재탕   개판  다이애나     끊   박정희  약했   발단  에서부터   써도\n",
       "명작   로라   진진     싯    모건  드라마틱  쵝오   재밌    완벽  월요일\n",
       "별로   다이   더냐    동거    방어    퇴화  당혹  어설프  횡설수설   밥맛\n",
       "유치   재주   단조    나열  무미건조     빤  걸렸    망    나사   근거\n",
       "답답   온갖    ㅓ   달려가    아휴    내려  강조  모니터    봐온   밥맛"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1_D_1_Layer_CNN\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>재미</th>\n",
       "      <td>네</td>\n",
       "      <td>애슐리</td>\n",
       "      <td>가물가물</td>\n",
       "      <td>바티칸</td>\n",
       "      <td>한국</td>\n",
       "      <td>약해서</td>\n",
       "      <td>녀</td>\n",
       "      <td>향해</td>\n",
       "      <td>췌</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>슬픔</th>\n",
       "      <td>시절</td>\n",
       "      <td>집중력</td>\n",
       "      <td>많</td>\n",
       "      <td>멋있</td>\n",
       "      <td>간다</td>\n",
       "      <td>best</td>\n",
       "      <td>동안</td>\n",
       "      <td>최고</td>\n",
       "      <td>블록버스터</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>아깝</th>\n",
       "      <td>접속</td>\n",
       "      <td>글</td>\n",
       "      <td>버림</td>\n",
       "      <td>불가</td>\n",
       "      <td>쩝</td>\n",
       "      <td>뽕짝</td>\n",
       "      <td>0</td>\n",
       "      <td>꺅</td>\n",
       "      <td>제멋대로</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>명작</th>\n",
       "      <td>보냅니다</td>\n",
       "      <td>역시</td>\n",
       "      <td>춘</td>\n",
       "      <td>심오</td>\n",
       "      <td>완벽</td>\n",
       "      <td>여러</td>\n",
       "      <td>g</td>\n",
       "      <td>밋기</td>\n",
       "      <td>홀딱</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>별로</th>\n",
       "      <td>--;</td>\n",
       "      <td>신파극</td>\n",
       "      <td>씨발</td>\n",
       "      <td>내리</td>\n",
       "      <td>더러움</td>\n",
       "      <td>차라리</td>\n",
       "      <td>날렸</td>\n",
       "      <td>밋밋</td>\n",
       "      <td>살인</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>유치</th>\n",
       "      <td>뭔</td>\n",
       "      <td>재미없</td>\n",
       "      <td>도망</td>\n",
       "      <td>칭찬</td>\n",
       "      <td>패러디</td>\n",
       "      <td>저러</td>\n",
       "      <td>제작비</td>\n",
       "      <td>...;;;</td>\n",
       "      <td>유치뽕</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>답답</th>\n",
       "      <td>겉멋</td>\n",
       "      <td>무식</td>\n",
       "      <td>미국식</td>\n",
       "      <td>권</td>\n",
       "      <td>무적</td>\n",
       "      <td>앉</td>\n",
       "      <td>명치</td>\n",
       "      <td>초등학생</td>\n",
       "      <td>영상물</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       1    2     3    4    5     6    7       8      9\n",
       "재미     네  애슐리  가물가물  바티칸   한국   약해서    녀      향해      췌\n",
       "슬픔    시절  집중력     많   멋있   간다  best   동안      최고  블록버스터\n",
       "아깝    접속    글    버림   불가    쩝    뽕짝    0       꺅   제멋대로\n",
       "명작  보냅니다   역시     춘   심오   완벽    여러    g      밋기     홀딱\n",
       "별로   --;  신파극    씨발   내리  더러움   차라리   날렸      밋밋     살인\n",
       "유치     뭔  재미없    도망   칭찬  패러디    저러  제작비  ...;;;    유치뽕\n",
       "답답    겉멋   무식   미국식    권   무적     앉   명치    초등학생    영상물"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(len(word_vectors)): \n",
    "    print(model_names[i])\n",
    "    test_word2vector(word_vectors[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portuguese-knight",
   "metadata": {},
   "source": [
    "## 한국어 Word2Vec 임베딩 활용하여 성능개선\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extreme-adams",
   "metadata": {},
   "source": [
    "#### 한국어 Word2Vec load\n",
    "- 프로젝트를 위하여 세가지 word2vector를 사용하기로 하였다.\n",
    "1. https://github.com/Kyubyong/wordvectors 에서 제공하는 Pre-trained model\n",
    "2. https://github.com/Kyubyong/wordvectors 에서 제공하는 코드를 이용하여 생성한 wikipedia 데이터 기반의 word2vector\n",
    "3. https://ratsgo.github.io/embedding/downloaddata.html 에서 제공하는 단어 수준의 임베딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cosmetic-disposition",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kyubyong  suheeeee  word-embeddings  wordvectors\r\n"
     ]
    }
   ],
   "source": [
    "!ls ./data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "defined-roberts",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "paths = [ workspace_path + '/data/Kyubyong/ko.bin',\n",
    "          workspace_path + '/data/wordvectors/data/ko.bin', \n",
    "          workspace_path + '/data/word-embeddings/word2vec' ]\n",
    "wvs = [ word2vec.Word2Vec.load(path) for path in paths ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "developmental-summer",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30185, 200)\n",
      "(10007, 100)\n",
      "(358043, 100)\n"
     ]
    }
   ],
   "source": [
    "for wv in wvs: print(wv.wv.vectors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upper-ordinary",
   "metadata": {},
   "source": [
    "#### word2vector 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "level-mining",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>재미</th>\n",
       "      <td>유머</td>\n",
       "      <td>매력</td>\n",
       "      <td>흥미</td>\n",
       "      <td>공짜</td>\n",
       "      <td>일자리</td>\n",
       "      <td>즐거움</td>\n",
       "      <td>비애</td>\n",
       "      <td>관객</td>\n",
       "      <td>향수</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>지루</th>\n",
       "      <td>편안</td>\n",
       "      <td>솔직</td>\n",
       "      <td>쓸쓸</td>\n",
       "      <td>차분</td>\n",
       "      <td>조용</td>\n",
       "      <td>냉정</td>\n",
       "      <td>자유분방</td>\n",
       "      <td>피곤</td>\n",
       "      <td>느긋</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>아깝</th>\n",
       "      <td>딱하</td>\n",
       "      <td>번거롭</td>\n",
       "      <td>아쉽</td>\n",
       "      <td>부끄럽</td>\n",
       "      <td>못마땅</td>\n",
       "      <td>편하</td>\n",
       "      <td>무난</td>\n",
       "      <td>애석</td>\n",
       "      <td>의아</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>명작</th>\n",
       "      <td>작품</td>\n",
       "      <td>대작</td>\n",
       "      <td>희극</td>\n",
       "      <td>희곡</td>\n",
       "      <td>거장</td>\n",
       "      <td>대표작</td>\n",
       "      <td>단편집</td>\n",
       "      <td>히트곡</td>\n",
       "      <td>가곡</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>별로</th>\n",
       "      <td>지역별</td>\n",
       "      <td>전혀</td>\n",
       "      <td>각기</td>\n",
       "      <td>개별</td>\n",
       "      <td>따로</td>\n",
       "      <td>마다</td>\n",
       "      <td>별</td>\n",
       "      <td>딱히</td>\n",
       "      <td>다소</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>유치</th>\n",
       "      <td>추진</td>\n",
       "      <td>확충</td>\n",
       "      <td>입주</td>\n",
       "      <td>선진화</td>\n",
       "      <td>육성</td>\n",
       "      <td>모금</td>\n",
       "      <td>신공항</td>\n",
       "      <td>확보</td>\n",
       "      <td>홍보</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>답답</th>\n",
       "      <td>무뚝뚝</td>\n",
       "      <td>난감</td>\n",
       "      <td>지저분</td>\n",
       "      <td>난잡</td>\n",
       "      <td>불쾌</td>\n",
       "      <td>비통</td>\n",
       "      <td>안타깝</td>\n",
       "      <td>멍청</td>\n",
       "      <td>간절</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      1    2    3    4    5    6     7    8   9\n",
       "재미   유머   매력   흥미   공짜  일자리  즐거움    비애   관객  향수\n",
       "지루   편안   솔직   쓸쓸   차분   조용   냉정  자유분방   피곤  느긋\n",
       "아깝   딱하  번거롭   아쉽  부끄럽  못마땅   편하    무난   애석  의아\n",
       "명작   작품   대작   희극   희곡   거장  대표작   단편집  히트곡  가곡\n",
       "별로  지역별   전혀   각기   개별   따로   마다     별   딱히  다소\n",
       "유치   추진   확충   입주  선진화   육성   모금   신공항   확보  홍보\n",
       "답답  무뚝뚝   난감  지저분   난잡   불쾌   비통   안타깝   멍청  간절"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>재미</th>\n",
       "      <td>흥미</td>\n",
       "      <td>외모</td>\n",
       "      <td>매력</td>\n",
       "      <td>관객</td>\n",
       "      <td>면모</td>\n",
       "      <td>목소리</td>\n",
       "      <td>인기</td>\n",
       "      <td>분위기</td>\n",
       "      <td>재주</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>별로</th>\n",
       "      <td>별</td>\n",
       "      <td>지역별</td>\n",
       "      <td>따로</td>\n",
       "      <td>개별</td>\n",
       "      <td>전혀</td>\n",
       "      <td>각</td>\n",
       "      <td>마다</td>\n",
       "      <td>그다지</td>\n",
       "      <td>문항</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>유치</th>\n",
       "      <td>추진</td>\n",
       "      <td>확보</td>\n",
       "      <td>모금</td>\n",
       "      <td>마련</td>\n",
       "      <td>확충</td>\n",
       "      <td>조달</td>\n",
       "      <td>개설</td>\n",
       "      <td>육성</td>\n",
       "      <td>충당</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     1    2   3   4   5    6   7    8   9\n",
       "재미  흥미   외모  매력  관객  면모  목소리  인기  분위기  재주\n",
       "별로   별  지역별  따로  개별  전혀    각  마다  그다지  문항\n",
       "유치  추진   확보  모금  마련  확충   조달  개설   육성  충당"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>재미</th>\n",
       "      <td>재미있</td>\n",
       "      <td>스릴감</td>\n",
       "      <td>재밌</td>\n",
       "      <td>스토리</td>\n",
       "      <td>~~~~~~~~</td>\n",
       "      <td>^^*</td>\n",
       "      <td>정말</td>\n",
       "      <td>무지무지</td>\n",
       "      <td>스릴</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>지루</th>\n",
       "      <td>흥미진진</td>\n",
       "      <td>졸립</td>\n",
       "      <td>찝찝</td>\n",
       "      <td>따분</td>\n",
       "      <td>..;;</td>\n",
       "      <td>산만</td>\n",
       "      <td>식상</td>\n",
       "      <td>갑갑</td>\n",
       "      <td>뻔해서</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>아깝</th>\n",
       "      <td>아까운</td>\n",
       "      <td>아까워</td>\n",
       "      <td>아까울</td>\n",
       "      <td>아까웠</td>\n",
       "      <td>진짜</td>\n",
       "      <td>..</td>\n",
       "      <td>반개</td>\n",
       "      <td>...</td>\n",
       "      <td>안타까워서</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>명작</th>\n",
       "      <td>걸작</td>\n",
       "      <td>졸작</td>\n",
       "      <td>.!!</td>\n",
       "      <td>정말</td>\n",
       "      <td>....</td>\n",
       "      <td>...</td>\n",
       "      <td>..</td>\n",
       "      <td>작품</td>\n",
       "      <td>~~~~~~~</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>별로</th>\n",
       "      <td>딱히</td>\n",
       "      <td>솔직히</td>\n",
       "      <td>별루</td>\n",
       "      <td>별론데</td>\n",
       "      <td>꽤</td>\n",
       "      <td>~~~~~~~~</td>\n",
       "      <td>그냥저냥</td>\n",
       "      <td>괜찬고</td>\n",
       "      <td>그래도</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>유치</th>\n",
       "      <td>기대</td>\n",
       "      <td>오글거리</td>\n",
       "      <td>.;;;</td>\n",
       "      <td>던데요</td>\n",
       "      <td>암튼</td>\n",
       "      <td>갑갑</td>\n",
       "      <td>정말</td>\n",
       "      <td>..;;</td>\n",
       "      <td>봣습니다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>답답</th>\n",
       "      <td>갑갑</td>\n",
       "      <td>찝찝</td>\n",
       "      <td>산만</td>\n",
       "      <td>눈쌀</td>\n",
       "      <td>흐뭇</td>\n",
       "      <td>졸립</td>\n",
       "      <td>피곤</td>\n",
       "      <td>찜찜</td>\n",
       "      <td>깝깝</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       1     2     3    4         5         6     7     8        9\n",
       "재미   재미있   스릴감    재밌  스토리  ~~~~~~~~       ^^*    정말  무지무지       스릴\n",
       "지루  흥미진진    졸립    찝찝   따분      ..;;        산만    식상    갑갑      뻔해서\n",
       "아깝   아까운   아까워   아까울  아까웠        진짜        ..    반개   ...    안타까워서\n",
       "명작    걸작    졸작   .!!   정말      ....       ...    ..    작품  ~~~~~~~\n",
       "별로    딱히   솔직히    별루  별론데         꽤  ~~~~~~~~  그냥저냥   괜찬고      그래도\n",
       "유치    기대  오글거리  .;;;  던데요        암튼        갑갑    정말  ..;;     봣습니다\n",
       "답답    갑갑    찝찝    산만   눈쌀        흐뭇        졸립    피곤    찜찜       깝깝"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for wv in wvs: test_word2vector(wv.wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behind-anger",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "첫번째 것이 가장 성능이 좋고 그 다음음 마지막 것"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjusted-maldives",
   "metadata": {},
   "source": [
    "#### 모델의 임베딩 레이어를 Word2Vec의 것으로 교체"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continental-proceeding",
   "metadata": {},
   "source": [
    "- embedding matrix 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "interstate-journalism",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel-dj1/anaconda3/envs/aiffel/lib/python3.7/site-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  \n",
      "/home/aiffel-dj1/anaconda3/envs/aiffel/lib/python3.7/site-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(word_to_index.keys()) \n",
    "embedding_matrixs = [ get_embedding_matrix(vocab_size, \n",
    "                                           wv.wv.vectors.shape[1], \n",
    "                                           index_to_word, wv) for wv in wvs ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gentle-worker",
   "metadata": {},
   "source": [
    "#### embedding matrix를 적용한 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "front-mining",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel-dj1/anaconda3/envs/aiffel/lib/python3.7/site-packages/ipykernel_launcher.py:3: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_16 (Embedding)     (None, 41, 200)           2000000   \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 8)                 6688      \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,006,769\n",
      "Trainable params: 2,006,769\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_17 (Embedding)     (None, 41, 200)           2000000   \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 35, 16)            22416     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 7, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 1, 16)             1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_8 (Glob (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,024,369\n",
      "Trainable params: 2,024,369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_18 (Embedding)     (None, 41, 200)           2000000   \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_9 (Glob (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 8)                 1608      \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,001,617\n",
      "Trainable params: 2,001,617\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel-dj1/anaconda3/envs/aiffel/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_19 (Embedding)     (None, 41, 100)           1000000   \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 8)                 3488      \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 1,003,569\n",
      "Trainable params: 1,003,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_20 (Embedding)     (None, 41, 100)           1000000   \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 35, 16)            11216     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 7, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 1, 16)             1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_10 (Glo (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 1,013,169\n",
      "Trainable params: 1,013,169\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_21 (Embedding)     (None, 41, 100)           1000000   \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_11 (Glo (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 8)                 808       \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 1,000,817\n",
      "Trainable params: 1,000,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_22 (Embedding)     (None, 41, 100)           1000000   \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 8)                 3488      \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 1,003,569\n",
      "Trainable params: 1,003,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_23 (Embedding)     (None, 41, 100)           1000000   \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 35, 16)            11216     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 7, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 1, 16)             1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_12 (Glo (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 1,013,169\n",
      "Trainable params: 1,013,169\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_24 (Embedding)     (None, 41, 100)           1000000   \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_13 (Glo (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 8)                 808       \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 1,000,817\n",
      "Trainable params: 1,000,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "word_vector_dims = [ wv.wv.vectors.shape[1] for wv in wvs ]\n",
    "model_group = [ [ get_rnn_model(vocab_size, word_vector_dims[i], 8, embedding_matrixs[i]),\n",
    "             get_one_d_cnn_model(vocab_size, word_vector_dims[i], embedding_matrixs[i]), \n",
    "             get_one_d_one_l_cnn_model(vocab_size, word_vector_dims[i], embedding_matrixs[i])] \n",
    "            for i in range(3) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "neural-aluminum",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[<tensorflow.python.keras.engine.sequential.Sequential at 0x7f83a8c65090>,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x7f83ebb23b50>,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x7f83ebfaddd0>],\n",
       " [<tensorflow.python.keras.engine.sequential.Sequential at 0x7f83eb7b3850>,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x7f8390ecdf50>,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x7f839052b450>],\n",
       " [<tensorflow.python.keras.engine.sequential.Sequential at 0x7f838fd787d0>,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x7f838d06fd90>,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x7f838c2fb350>]]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_group"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "committed-effort",
   "metadata": {},
   "source": [
    "#### 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "dressed-transfer",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start train RNN ============================================== \n",
      "Train on 136182 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "136182/136182 - 17s - loss: 0.5060 - acc: 0.7475 - val_loss: 0.3920 - val_acc: 0.8288\n",
      "Epoch 2/20\n",
      "136182/136182 - 17s - loss: 0.3572 - acc: 0.8457 - val_loss: 0.3569 - val_acc: 0.8443\n",
      "Epoch 3/20\n",
      "136182/136182 - 17s - loss: 0.3184 - acc: 0.8656 - val_loss: 0.3472 - val_acc: 0.8478\n",
      "Epoch 4/20\n",
      "136182/136182 - 17s - loss: 0.2967 - acc: 0.8766 - val_loss: 0.3444 - val_acc: 0.8523\n",
      "Epoch 5/20\n",
      "136182/136182 - 16s - loss: 0.2808 - acc: 0.8841 - val_loss: 0.3472 - val_acc: 0.8516\n",
      "Epoch 6/20\n",
      "136182/136182 - 17s - loss: 0.2676 - acc: 0.8907 - val_loss: 0.3609 - val_acc: 0.8491\n",
      "Epoch 7/20\n",
      "136182/136182 - 17s - loss: 0.2550 - acc: 0.8973 - val_loss: 0.3518 - val_acc: 0.8538\n",
      "Epoch 8/20\n",
      "136182/136182 - 16s - loss: 0.2431 - acc: 0.9024 - val_loss: 0.3585 - val_acc: 0.8524\n",
      "Epoch 00008: early stopping\n",
      "train completed ============================================== \n",
      "start train 1_D_CNN ============================================== \n",
      "Train on 136182 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "136182/136182 - 16s - loss: 0.5365 - acc: 0.7180 - val_loss: 0.4241 - val_acc: 0.8071\n",
      "Epoch 2/20\n",
      "136182/136182 - 16s - loss: 0.3797 - acc: 0.8314 - val_loss: 0.3692 - val_acc: 0.8387\n",
      "Epoch 3/20\n",
      "136182/136182 - 16s - loss: 0.3250 - acc: 0.8617 - val_loss: 0.3483 - val_acc: 0.8514\n",
      "Epoch 4/20\n",
      "136182/136182 - 16s - loss: 0.2912 - acc: 0.8803 - val_loss: 0.3416 - val_acc: 0.8531\n",
      "Epoch 5/20\n",
      "136182/136182 - 16s - loss: 0.2666 - acc: 0.8935 - val_loss: 0.3523 - val_acc: 0.8521\n",
      "Epoch 6/20\n",
      "136182/136182 - 15s - loss: 0.2474 - acc: 0.9033 - val_loss: 0.3655 - val_acc: 0.8478\n",
      "Epoch 7/20\n",
      "136182/136182 - 15s - loss: 0.2247 - acc: 0.9147 - val_loss: 0.3712 - val_acc: 0.8508\n",
      "Epoch 8/20\n",
      "136182/136182 - 15s - loss: 0.2054 - acc: 0.9234 - val_loss: 0.3876 - val_acc: 0.8474\n",
      "Epoch 00008: early stopping\n",
      "train completed ============================================== \n",
      "start train 1_D_1_Layer_CNN ============================================== \n",
      "Train on 136182 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "136182/136182 - 8s - loss: 0.6811 - acc: 0.5737 - val_loss: 0.6234 - val_acc: 0.6710\n",
      "Epoch 2/20\n",
      "136182/136182 - 8s - loss: 0.5669 - acc: 0.7126 - val_loss: 0.5307 - val_acc: 0.7365\n",
      "Epoch 3/20\n",
      "136182/136182 - 8s - loss: 0.4847 - acc: 0.7688 - val_loss: 0.4680 - val_acc: 0.7786\n",
      "Epoch 4/20\n",
      "136182/136182 - 8s - loss: 0.4374 - acc: 0.7978 - val_loss: 0.4398 - val_acc: 0.7991\n",
      "Epoch 5/20\n",
      "136182/136182 - 8s - loss: 0.4054 - acc: 0.8171 - val_loss: 0.4238 - val_acc: 0.8050\n",
      "Epoch 6/20\n",
      "136182/136182 - 8s - loss: 0.3820 - acc: 0.8303 - val_loss: 0.4094 - val_acc: 0.8157\n",
      "Epoch 7/20\n",
      "136182/136182 - 8s - loss: 0.3624 - acc: 0.8408 - val_loss: 0.4021 - val_acc: 0.8224\n",
      "Epoch 8/20\n",
      "136182/136182 - 8s - loss: 0.3463 - acc: 0.8492 - val_loss: 0.3954 - val_acc: 0.8245\n",
      "Epoch 9/20\n",
      "136182/136182 - 8s - loss: 0.3315 - acc: 0.8576 - val_loss: 0.3912 - val_acc: 0.8296\n",
      "Epoch 10/20\n",
      "136182/136182 - 8s - loss: 0.3186 - acc: 0.8648 - val_loss: 0.3877 - val_acc: 0.8321\n",
      "Epoch 11/20\n",
      "136182/136182 - 8s - loss: 0.3061 - acc: 0.8710 - val_loss: 0.3941 - val_acc: 0.8308\n",
      "Epoch 12/20\n",
      "136182/136182 - 8s - loss: 0.2947 - acc: 0.8763 - val_loss: 0.3999 - val_acc: 0.8272\n",
      "Epoch 13/20\n",
      "136182/136182 - 8s - loss: 0.2847 - acc: 0.8809 - val_loss: 0.3861 - val_acc: 0.8352\n",
      "Epoch 14/20\n",
      "136182/136182 - 8s - loss: 0.2730 - acc: 0.8872 - val_loss: 0.3869 - val_acc: 0.8354\n",
      "Epoch 15/20\n",
      "136182/136182 - 8s - loss: 0.2623 - acc: 0.8929 - val_loss: 0.3893 - val_acc: 0.8369\n",
      "Epoch 16/20\n",
      "136182/136182 - 8s - loss: 0.2526 - acc: 0.8980 - val_loss: 0.3914 - val_acc: 0.8363\n",
      "Epoch 17/20\n",
      "136182/136182 - 8s - loss: 0.2428 - acc: 0.9027 - val_loss: 0.3996 - val_acc: 0.8336\n",
      "Epoch 00017: early stopping\n",
      "train completed ============================================== \n",
      "start train RNN ============================================== \n",
      "Train on 136182 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "136182/136182 - 11s - loss: 0.5382 - acc: 0.7191 - val_loss: 0.4211 - val_acc: 0.8133\n",
      "Epoch 2/20\n",
      "136182/136182 - 11s - loss: 0.3826 - acc: 0.8340 - val_loss: 0.3743 - val_acc: 0.8390\n",
      "Epoch 3/20\n",
      "136182/136182 - 11s - loss: 0.3399 - acc: 0.8568 - val_loss: 0.3594 - val_acc: 0.8431\n",
      "Epoch 4/20\n",
      "136182/136182 - 10s - loss: 0.3182 - acc: 0.8672 - val_loss: 0.3568 - val_acc: 0.8477\n",
      "Epoch 5/20\n",
      "136182/136182 - 10s - loss: 0.3024 - acc: 0.8747 - val_loss: 0.3554 - val_acc: 0.8481\n",
      "Epoch 6/20\n",
      "136182/136182 - 10s - loss: 0.2905 - acc: 0.8813 - val_loss: 0.3553 - val_acc: 0.8482\n",
      "Epoch 7/20\n",
      "136182/136182 - 10s - loss: 0.2800 - acc: 0.8855 - val_loss: 0.3553 - val_acc: 0.8490\n",
      "Epoch 8/20\n",
      "136182/136182 - 10s - loss: 0.2708 - acc: 0.8899 - val_loss: 0.3616 - val_acc: 0.8482\n",
      "Epoch 9/20\n",
      "136182/136182 - 11s - loss: 0.2620 - acc: 0.8942 - val_loss: 0.3632 - val_acc: 0.8493\n",
      "Epoch 10/20\n",
      "136182/136182 - 10s - loss: 0.2538 - acc: 0.8979 - val_loss: 0.3613 - val_acc: 0.8484\n",
      "Epoch 00010: early stopping\n",
      "train completed ============================================== \n",
      "start train 1_D_CNN ============================================== \n",
      "Train on 136182 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "136182/136182 - 9s - loss: 0.5938 - acc: 0.6635 - val_loss: 0.4709 - val_acc: 0.7846\n",
      "Epoch 2/20\n",
      "136182/136182 - 9s - loss: 0.4170 - acc: 0.8106 - val_loss: 0.3921 - val_acc: 0.8262\n",
      "Epoch 3/20\n",
      "136182/136182 - 9s - loss: 0.3520 - acc: 0.8465 - val_loss: 0.3670 - val_acc: 0.8389\n",
      "Epoch 4/20\n",
      "136182/136182 - 9s - loss: 0.3179 - acc: 0.8644 - val_loss: 0.3599 - val_acc: 0.8432\n",
      "Epoch 5/20\n",
      "136182/136182 - 9s - loss: 0.2954 - acc: 0.8764 - val_loss: 0.3526 - val_acc: 0.8470\n",
      "Epoch 6/20\n",
      "136182/136182 - 9s - loss: 0.2785 - acc: 0.8849 - val_loss: 0.3605 - val_acc: 0.8465\n",
      "Epoch 7/20\n",
      "136182/136182 - 8s - loss: 0.2627 - acc: 0.8930 - val_loss: 0.3621 - val_acc: 0.8481\n",
      "Epoch 8/20\n",
      "136182/136182 - 8s - loss: 0.2488 - acc: 0.8998 - val_loss: 0.3769 - val_acc: 0.8405\n",
      "Epoch 9/20\n",
      "136182/136182 - 9s - loss: 0.2373 - acc: 0.9065 - val_loss: 0.3786 - val_acc: 0.8398\n",
      "Epoch 00009: early stopping\n",
      "train completed ============================================== \n",
      "start train 1_D_1_Layer_CNN ============================================== \n",
      "Train on 136182 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "136182/136182 - 5s - loss: 0.8422 - acc: 0.5390 - val_loss: 0.6724 - val_acc: 0.5967\n",
      "Epoch 2/20\n",
      "136182/136182 - 4s - loss: 0.6306 - acc: 0.6474 - val_loss: 0.5968 - val_acc: 0.6834\n",
      "Epoch 3/20\n",
      "136182/136182 - 4s - loss: 0.5681 - acc: 0.7082 - val_loss: 0.5450 - val_acc: 0.7292\n",
      "Epoch 4/20\n",
      "136182/136182 - 4s - loss: 0.5183 - acc: 0.7459 - val_loss: 0.5031 - val_acc: 0.7566\n",
      "Epoch 5/20\n",
      "136182/136182 - 4s - loss: 0.4787 - acc: 0.7714 - val_loss: 0.4737 - val_acc: 0.7748\n",
      "Epoch 6/20\n",
      "136182/136182 - 4s - loss: 0.4496 - acc: 0.7895 - val_loss: 0.4531 - val_acc: 0.7897\n",
      "Epoch 7/20\n",
      "136182/136182 - 4s - loss: 0.4269 - acc: 0.8027 - val_loss: 0.4377 - val_acc: 0.8001\n",
      "Epoch 8/20\n",
      "136182/136182 - 4s - loss: 0.4089 - acc: 0.8133 - val_loss: 0.4267 - val_acc: 0.8082\n",
      "Epoch 9/20\n",
      "136182/136182 - 4s - loss: 0.3939 - acc: 0.8223 - val_loss: 0.4187 - val_acc: 0.8128\n",
      "Epoch 10/20\n",
      "136182/136182 - 4s - loss: 0.3816 - acc: 0.8293 - val_loss: 0.4188 - val_acc: 0.8118\n",
      "Epoch 11/20\n",
      "136182/136182 - 4s - loss: 0.3703 - acc: 0.8359 - val_loss: 0.4065 - val_acc: 0.8211\n",
      "Epoch 12/20\n",
      "136182/136182 - 4s - loss: 0.3599 - acc: 0.8413 - val_loss: 0.4012 - val_acc: 0.8233\n",
      "Epoch 13/20\n",
      "136182/136182 - 5s - loss: 0.3507 - acc: 0.8463 - val_loss: 0.3971 - val_acc: 0.8253\n",
      "Epoch 14/20\n",
      "136182/136182 - 5s - loss: 0.3424 - acc: 0.8510 - val_loss: 0.3946 - val_acc: 0.8253\n",
      "Epoch 15/20\n",
      "136182/136182 - 4s - loss: 0.3337 - acc: 0.8553 - val_loss: 0.3932 - val_acc: 0.8286\n",
      "Epoch 16/20\n",
      "136182/136182 - 4s - loss: 0.3254 - acc: 0.8601 - val_loss: 0.3920 - val_acc: 0.8256\n",
      "Epoch 17/20\n",
      "136182/136182 - 4s - loss: 0.3185 - acc: 0.8638 - val_loss: 0.3895 - val_acc: 0.8319\n",
      "Epoch 18/20\n",
      "136182/136182 - 4s - loss: 0.3115 - acc: 0.8676 - val_loss: 0.3876 - val_acc: 0.8317\n",
      "Epoch 19/20\n",
      "136182/136182 - 4s - loss: 0.3040 - acc: 0.8712 - val_loss: 0.3905 - val_acc: 0.8303\n",
      "Epoch 20/20\n",
      "136182/136182 - 4s - loss: 0.2985 - acc: 0.8740 - val_loss: 0.3879 - val_acc: 0.8320\n",
      "train completed ============================================== \n",
      "start train RNN ============================================== \n",
      "Train on 136182 samples, validate on 10000 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "136182/136182 - 11s - loss: 0.4676 - acc: 0.7735 - val_loss: 0.3659 - val_acc: 0.8452\n",
      "Epoch 2/20\n",
      "136182/136182 - 10s - loss: 0.3422 - acc: 0.8563 - val_loss: 0.3440 - val_acc: 0.8544\n",
      "Epoch 3/20\n",
      "136182/136182 - 10s - loss: 0.3133 - acc: 0.8705 - val_loss: 0.3451 - val_acc: 0.8543\n",
      "Epoch 4/20\n",
      "136182/136182 - 11s - loss: 0.2963 - acc: 0.8787 - val_loss: 0.3451 - val_acc: 0.8559\n",
      "Epoch 5/20\n",
      "136182/136182 - 12s - loss: 0.2838 - acc: 0.8842 - val_loss: 0.3403 - val_acc: 0.8559\n",
      "Epoch 6/20\n",
      "136182/136182 - 10s - loss: 0.2722 - acc: 0.8906 - val_loss: 0.3414 - val_acc: 0.8558\n",
      "Epoch 7/20\n",
      "136182/136182 - 10s - loss: 0.2616 - acc: 0.8952 - val_loss: 0.3483 - val_acc: 0.8535\n",
      "Epoch 8/20\n",
      "136182/136182 - 10s - loss: 0.2516 - acc: 0.9003 - val_loss: 0.3511 - val_acc: 0.8551\n",
      "Epoch 9/20\n",
      "136182/136182 - 10s - loss: 0.2422 - acc: 0.9052 - val_loss: 0.3550 - val_acc: 0.8528\n",
      "Epoch 00009: early stopping\n",
      "train completed ============================================== \n",
      "start train 1_D_CNN ============================================== \n",
      "Train on 136182 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "136182/136182 - 8s - loss: 0.4823 - acc: 0.7641 - val_loss: 0.3643 - val_acc: 0.8401\n",
      "Epoch 2/20\n",
      "136182/136182 - 8s - loss: 0.3394 - acc: 0.8536 - val_loss: 0.3457 - val_acc: 0.8488\n",
      "Epoch 3/20\n",
      "136182/136182 - 8s - loss: 0.3051 - acc: 0.8713 - val_loss: 0.3385 - val_acc: 0.8534\n",
      "Epoch 4/20\n",
      "136182/136182 - 8s - loss: 0.2781 - acc: 0.8847 - val_loss: 0.3383 - val_acc: 0.8582\n",
      "Epoch 5/20\n",
      "136182/136182 - 8s - loss: 0.2536 - acc: 0.8970 - val_loss: 0.3492 - val_acc: 0.8562\n",
      "Epoch 6/20\n",
      "136182/136182 - 8s - loss: 0.2261 - acc: 0.9105 - val_loss: 0.3639 - val_acc: 0.8508\n",
      "Epoch 7/20\n",
      "136182/136182 - 9s - loss: 0.1962 - acc: 0.9252 - val_loss: 0.3973 - val_acc: 0.8495\n",
      "Epoch 8/20\n",
      "136182/136182 - 8s - loss: 0.1687 - acc: 0.9379 - val_loss: 0.4071 - val_acc: 0.8485\n",
      "Epoch 00008: early stopping\n",
      "train completed ============================================== \n",
      "start train 1_D_1_Layer_CNN ============================================== \n",
      "Train on 136182 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "136182/136182 - 5s - loss: 0.6268 - acc: 0.6806 - val_loss: 0.4935 - val_acc: 0.7946\n",
      "Epoch 2/20\n",
      "136182/136182 - 4s - loss: 0.4172 - acc: 0.8164 - val_loss: 0.3798 - val_acc: 0.8316\n",
      "Epoch 3/20\n",
      "136182/136182 - 4s - loss: 0.3556 - acc: 0.8450 - val_loss: 0.3565 - val_acc: 0.8418\n",
      "Epoch 4/20\n",
      "136182/136182 - 4s - loss: 0.3280 - acc: 0.8599 - val_loss: 0.3465 - val_acc: 0.8488\n",
      "Epoch 5/20\n",
      "136182/136182 - 4s - loss: 0.3079 - acc: 0.8706 - val_loss: 0.3420 - val_acc: 0.8485\n",
      "Epoch 6/20\n",
      "136182/136182 - 4s - loss: 0.2912 - acc: 0.8792 - val_loss: 0.3407 - val_acc: 0.8518\n",
      "Epoch 7/20\n",
      "136182/136182 - 4s - loss: 0.2769 - acc: 0.8862 - val_loss: 0.3403 - val_acc: 0.8547\n",
      "Epoch 8/20\n",
      "136182/136182 - 4s - loss: 0.2637 - acc: 0.8931 - val_loss: 0.3435 - val_acc: 0.8535\n",
      "Epoch 9/20\n",
      "136182/136182 - 4s - loss: 0.2517 - acc: 0.8990 - val_loss: 0.3461 - val_acc: 0.8531\n",
      "Epoch 10/20\n",
      "136182/136182 - 4s - loss: 0.2398 - acc: 0.9051 - val_loss: 0.3528 - val_acc: 0.8521\n",
      "Epoch 11/20\n",
      "136182/136182 - 4s - loss: 0.2286 - acc: 0.9111 - val_loss: 0.3575 - val_acc: 0.8526\n",
      "Epoch 00011: early stopping\n",
      "train completed ============================================== \n"
     ]
    }
   ],
   "source": [
    "histories = []\n",
    "for models in model_group:\n",
    "    for i in range(len(models)):\n",
    "        histories.append(train(models[i], model_names[i], X_train, y_train, X_val, y_val, epochs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlled-currency",
   "metadata": {},
   "source": [
    "#### 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "dried-packet",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word2vec number :: 0\n",
      "49157/49157 - 7s - loss: 0.3677 - acc: 0.8501\n",
      "49157/49157 - 2s - loss: 0.4015 - acc: 0.8426\n",
      "49157/49157 - 1s - loss: 0.4099 - acc: 0.8279\n",
      "word2vec number :: 1\n",
      "49157/49157 - 7s - loss: 0.3693 - acc: 0.8480\n",
      "49157/49157 - 1s - loss: 0.3865 - acc: 0.8404\n",
      "49157/49157 - 1s - loss: 0.4011 - acc: 0.8256\n",
      "word2vec number :: 2\n",
      "49157/49157 - 6s - loss: 0.3640 - acc: 0.8479\n",
      "49157/49157 - 1s - loss: 0.4134 - acc: 0.8455\n",
      "49157/49157 - 1s - loss: 0.3715 - acc: 0.8458\n"
     ]
    }
   ],
   "source": [
    "for model_idx in range(len(model_group)):\n",
    "    print('word2vec number :: {}'.format(model_idx))\n",
    "    evaluation_res = [ model_group[model_idx][i].evaluate(X_test,  y_test, verbose=2)\n",
    "                       for i in range(len(model_group[model_idx])) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stretch-marker",
   "metadata": {},
   "source": [
    "#### 추가실험\n",
    "- 결과가 가장 좋은 첫번째 word2vec와 rnn 모델을 이용하여 더 좋은 결과를 얻기 위해 하이퍼 파리미터를 조정해 보고자 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "demanding-westminster",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel-dj1/anaconda3/envs/aiffel/lib/python3.7/site-packages/ipykernel_launcher.py:3: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_31 (Embedding)     (None, 41, 200)           2000000   \n",
      "_________________________________________________________________\n",
      "lstm_16 (LSTM)               (None, 16)                13888     \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 2,014,177\n",
      "Trainable params: 2,014,177\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_32 (Embedding)     (None, 41, 200)           2000000   \n",
      "_________________________________________________________________\n",
      "lstm_17 (LSTM)               (None, 32)                29824     \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 2,030,913\n",
      "Trainable params: 2,030,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_35\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_33 (Embedding)     (None, 41, 200)           2000000   \n",
      "_________________________________________________________________\n",
      "lstm_18 (LSTM)               (None, 64)                67840     \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 2,072,065\n",
      "Trainable params: 2,072,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_34 (Embedding)     (None, 41, 200)           2000000   \n",
      "_________________________________________________________________\n",
      "lstm_19 (LSTM)               (None, 128)               168448    \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 2,185,089\n",
      "Trainable params: 2,185,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_37\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_35 (Embedding)     (None, 41, 200)           2000000   \n",
      "_________________________________________________________________\n",
      "lstm_20 (LSTM)               (None, 256)               467968    \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,534,017\n",
      "Trainable params: 2,534,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "word_vector_dims = wvs[0].wv.vectors.shape[1]\n",
    "vocab_size = len(word_to_index.keys()) \n",
    "\n",
    "rnn_models = [ get_rnn_model(vocab_size, word_vector_dims, 16, embedding_matrixs[0]),\n",
    "               get_rnn_model(vocab_size, word_vector_dims, 32, embedding_matrixs[0]),\n",
    "               get_rnn_model(vocab_size, word_vector_dims, 64, embedding_matrixs[0]),\n",
    "               get_rnn_model(vocab_size, word_vector_dims, 128, embedding_matrixs[0]),\n",
    "               get_rnn_model(vocab_size, word_vector_dims, 256, embedding_matrixs[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "oriented-tyler",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start train RNN ============================================== \n",
      "Train on 136182 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "136182/136182 - 19s - loss: 0.4977 - acc: 0.7506 - val_loss: 0.3878 - val_acc: 0.8277\n",
      "Epoch 2/20\n",
      "136182/136182 - 17s - loss: 0.3495 - acc: 0.8489 - val_loss: 0.3457 - val_acc: 0.8529\n",
      "Epoch 3/20\n",
      "136182/136182 - 17s - loss: 0.3092 - acc: 0.8697 - val_loss: 0.3383 - val_acc: 0.8545\n",
      "Epoch 4/20\n",
      "136182/136182 - 17s - loss: 0.2855 - acc: 0.8812 - val_loss: 0.3360 - val_acc: 0.8588\n",
      "Epoch 5/20\n",
      "136182/136182 - 18s - loss: 0.2681 - acc: 0.8904 - val_loss: 0.3409 - val_acc: 0.8556\n",
      "Epoch 6/20\n",
      "136182/136182 - 20s - loss: 0.2521 - acc: 0.8972 - val_loss: 0.3475 - val_acc: 0.8539\n",
      "Epoch 7/20\n",
      "136182/136182 - 19s - loss: 0.2380 - acc: 0.9043 - val_loss: 0.3557 - val_acc: 0.8551\n",
      "Epoch 8/20\n",
      "136182/136182 - 19s - loss: 0.2227 - acc: 0.9113 - val_loss: 0.3628 - val_acc: 0.8595\n",
      "Epoch 00008: early stopping\n",
      "train completed ============================================== \n",
      "start train RNN ============================================== \n",
      "Train on 136182 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "136182/136182 - 24s - loss: 0.4730 - acc: 0.7686 - val_loss: 0.3686 - val_acc: 0.8398\n",
      "Epoch 2/20\n",
      "136182/136182 - 22s - loss: 0.3384 - acc: 0.8544 - val_loss: 0.3345 - val_acc: 0.8566\n",
      "Epoch 3/20\n",
      "136182/136182 - 21s - loss: 0.2990 - acc: 0.8745 - val_loss: 0.3270 - val_acc: 0.8593\n",
      "Epoch 4/20\n",
      "136182/136182 - 22s - loss: 0.2735 - acc: 0.8867 - val_loss: 0.3250 - val_acc: 0.8619\n",
      "Epoch 5/20\n",
      "136182/136182 - 22s - loss: 0.2535 - acc: 0.8970 - val_loss: 0.3295 - val_acc: 0.8610\n",
      "Epoch 6/20\n",
      "136182/136182 - 22s - loss: 0.2338 - acc: 0.9059 - val_loss: 0.3321 - val_acc: 0.8648\n",
      "Epoch 7/20\n",
      "136182/136182 - 22s - loss: 0.2165 - acc: 0.9140 - val_loss: 0.3438 - val_acc: 0.8623\n",
      "Epoch 8/20\n",
      "136182/136182 - 21s - loss: 0.2018 - acc: 0.9213 - val_loss: 0.3558 - val_acc: 0.8625\n",
      "Epoch 00008: early stopping\n",
      "train completed ============================================== \n",
      "start train RNN ============================================== \n",
      "Train on 136182 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "136182/136182 - 35s - loss: 0.4510 - acc: 0.7827 - val_loss: 0.3594 - val_acc: 0.8398\n",
      "Epoch 2/20\n",
      "136182/136182 - 31s - loss: 0.3255 - acc: 0.8588 - val_loss: 0.3293 - val_acc: 0.8583\n",
      "Epoch 3/20\n",
      "136182/136182 - 31s - loss: 0.2866 - acc: 0.8790 - val_loss: 0.3238 - val_acc: 0.8577\n",
      "Epoch 4/20\n",
      "136182/136182 - 35s - loss: 0.2612 - acc: 0.8913 - val_loss: 0.3188 - val_acc: 0.8609\n",
      "Epoch 5/20\n",
      "136182/136182 - 35s - loss: 0.2388 - acc: 0.9019 - val_loss: 0.3287 - val_acc: 0.8629\n",
      "Epoch 6/20\n",
      "136182/136182 - 35s - loss: 0.2184 - acc: 0.9111 - val_loss: 0.3468 - val_acc: 0.8586\n",
      "Epoch 7/20\n",
      "136182/136182 - 34s - loss: 0.1979 - acc: 0.9210 - val_loss: 0.3407 - val_acc: 0.8620\n",
      "Epoch 8/20\n",
      "136182/136182 - 32s - loss: 0.1773 - acc: 0.9306 - val_loss: 0.3682 - val_acc: 0.8608\n",
      "Epoch 00008: early stopping\n",
      "train completed ============================================== \n",
      "start train RNN ============================================== \n",
      "Train on 136182 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "136182/136182 - 53s - loss: 0.4442 - acc: 0.7874 - val_loss: 0.3566 - val_acc: 0.8432\n",
      "Epoch 2/20\n",
      "136182/136182 - 53s - loss: 0.3170 - acc: 0.8634 - val_loss: 0.3193 - val_acc: 0.8609\n",
      "Epoch 3/20\n",
      "136182/136182 - 51s - loss: 0.2764 - acc: 0.8836 - val_loss: 0.3111 - val_acc: 0.8641\n",
      "Epoch 4/20\n",
      "136182/136182 - 54s - loss: 0.2464 - acc: 0.8984 - val_loss: 0.3138 - val_acc: 0.8670\n",
      "Epoch 5/20\n",
      "136182/136182 - 55s - loss: 0.2200 - acc: 0.9104 - val_loss: 0.3254 - val_acc: 0.8714\n",
      "Epoch 6/20\n",
      "136182/136182 - 56s - loss: 0.1937 - acc: 0.9223 - val_loss: 0.3277 - val_acc: 0.8678\n",
      "Epoch 7/20\n",
      "136182/136182 - 55s - loss: 0.1667 - acc: 0.9343 - val_loss: 0.3711 - val_acc: 0.8672\n",
      "Epoch 00007: early stopping\n",
      "train completed ============================================== \n",
      "start train RNN ============================================== \n",
      "Train on 136182 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "136182/136182 - 116s - loss: 0.4317 - acc: 0.7952 - val_loss: 0.3428 - val_acc: 0.8546\n",
      "Epoch 2/20\n",
      "136182/136182 - 114s - loss: 0.3110 - acc: 0.8666 - val_loss: 0.3137 - val_acc: 0.8654\n",
      "Epoch 3/20\n",
      "136182/136182 - 113s - loss: 0.2676 - acc: 0.8875 - val_loss: 0.3091 - val_acc: 0.8707\n",
      "Epoch 4/20\n",
      "136182/136182 - 104s - loss: 0.2343 - acc: 0.9037 - val_loss: 0.3050 - val_acc: 0.8725\n",
      "Epoch 5/20\n",
      "136182/136182 - 102s - loss: 0.1993 - acc: 0.9199 - val_loss: 0.3234 - val_acc: 0.8716\n",
      "Epoch 6/20\n",
      "136182/136182 - 103s - loss: 0.1614 - acc: 0.9362 - val_loss: 0.3497 - val_acc: 0.8670\n",
      "Epoch 7/20\n",
      "136182/136182 - 103s - loss: 0.1260 - acc: 0.9508 - val_loss: 0.4221 - val_acc: 0.8594\n",
      "Epoch 8/20\n",
      "136182/136182 - 92s - loss: 0.0957 - acc: 0.9627 - val_loss: 0.5029 - val_acc: 0.8610\n",
      "Epoch 00008: early stopping\n",
      "train completed ============================================== \n"
     ]
    }
   ],
   "source": [
    "rnn_models_history = [train(model, model_names[0], X_train, y_train, X_val, y_val, 20)\n",
    "                      for model in rnn_models ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "unique-crown",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49157/49157 - 6s - loss: 0.3705 - acc: 0.8526\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3704558219982323, 0.8525744]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_models[0].evaluate(X_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "rapid-destruction",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49157/49157 - 6s - loss: 0.3705 - acc: 0.8526\n",
      "49157/49157 - 7s - loss: 0.3661 - acc: 0.8555\n",
      "49157/49157 - 7s - loss: 0.3715 - acc: 0.8567\n",
      "49157/49157 - 11s - loss: 0.3848 - acc: 0.8611\n",
      "49157/49157 - 28s - loss: 0.5107 - acc: 0.8587\n"
     ]
    }
   ],
   "source": [
    "evaluation_res = [ rnn_models[i].evaluate(X_test,  y_test, verbose=2) for i in range(len(rnn_models)) ]\n",
    "df = pd.DataFrame(evaluation_res, index=[16,32,64,128,256], columns=['loss', 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "smart-programming",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.370456</td>\n",
       "      <td>0.852574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.366094</td>\n",
       "      <td>0.855483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.371462</td>\n",
       "      <td>0.856704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0.384762</td>\n",
       "      <td>0.861139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>0.510656</td>\n",
       "      <td>0.858738</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss  accuracy\n",
       "16   0.370456  0.852574\n",
       "32   0.366094  0.855483\n",
       "64   0.371462  0.856704\n",
       "128  0.384762  0.861139\n",
       "256  0.510656  0.858738"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "final-socket",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## 결론\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "productive-progress",
   "metadata": {},
   "source": [
    "### 요약\n",
    "- 목표 : 네이버 영화리뷰 데이터셋을 이용하여 감성분류기를 만들어 본다.\n",
    "- 프로젝트 진행 과정\n",
    "    - 데이터 전처리\n",
    "        - 네이버 영화 리뷰 데이터셋을 다운로드 받아 불러들인다. [link](https://github.com/e9t/nsmc)\n",
    "        - 데이터 로더를 구성하여 데이터 중복제거, Mecab 토크나이저를 이용한 토큰화 등의 과정을 걸쳐 데이터를 컴퓨터가 이해할 수 있도록 수치화 시킨다.\n",
    "        - 문장의 길이를 적절가게 조정하여 모든 문장이 같은 길이를 가지도록 변환한다.\n",
    "    - 모델 설계/훈련/평가 : RNN, 1-D Convolution Neural Network, Global max pooling Layer 하나만을 사용하는 모델 -> 총 3개의 모델을 사용하여 훈련을 시키고 accuracy와 loss를 구한다. 이때, accuracy와 loss를 그래로 나타내어 추이를 확인한다.\n",
    "    - embedding layer 분석\n",
    "         - 위의 모델에서 학습된 embedding 파라미터를 txt 파일로 저장후 gesim을 이용하여 다시 읽어들여 word vector로 사용한다.\n",
    "         - 단어 10개를 선정하여 word vector의 성능을 평가한다.\n",
    "    - 기존에 학습된 Word Embedding 모델을 읽어들여 위 모델의 성능을 향상 시켜본다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interior-reverse",
   "metadata": {},
   "source": [
    "### 프로젝트 평가\n",
    "1. 다양한 방법(3가지 이상의 모델)으로 Text Classification 태스크를 성공적으로 구현하였는가?\n",
    "- 3가지 모델을 수립하여 프로젝트를 진행하였고, 적절한 결과를 얻어내는 것에 성공하였다.\n",
    "\n",
    "2. gensim을 활용하여 자체학습된 혹은 사전학습된 임베딩 레이어를 분석하였는가? gensim의 유사단어 찾기를 활용하여 자체학습한 임베딩과 사전학습 임베딩을 적절히 분석하였는가?\n",
    "- 영화 평가에 자주 등장하는 7가지 단어(재미, 지루, 아깝, 명작, 별로, 유치, 답답)를 선정하여 자체학습한 임베딩과 사전학습 임베딩에서 위 단어와 가장 유사항 단어를 각 단어별로 10개씩 뽑내 내역을 확인하였다.\n",
    "- 프로젝트에서 총 3가지 사전학습 임베딩을 사용하였는데 유사단어 찾기에서 직관적으로 가장 좋은 성능을 보인 것은 세번째 임베딩이었다. 하지만, 이를 학습시킨 후 모델 성능 평가에서는 첫번째 임베딩이 가장 좋은 성능을 보여주었다.\n",
    "\n",
    "3. 한국어 Word2Vec을 활용하여 가시적인 성능향상을 달성하였는가? 네이버 영화리뷰 데이터 감성분석 정확도를 85% 이상 달성하였는가?\n",
    "-  같은 하이퍼 파마리터를 사용할였을 때, 다음과 같이 accuracy가 변화하였다.\n",
    "    | 모델 | 자제학습 | embedding1 | embedding2 | embedding3 |\n",
    "    |:----:|:--------:|:----------:|:----------:|:----------:|\n",
    "    | RNN  | 0.847875 | 0.8501     | 0.8480     | 0.8479     |\n",
    "    | 1-D CNN | 0.845251 | 0.8426  | 0.8404     | 0.8455     |\n",
    "    | GlobalMaxPooling1D | 0.840491 | 0.8279 | 0.8256 | 0.8458 |\n",
    "- 추가적으로 가장 성능이 좋았던 RNN-embedding1 조합을 이용하여 모델의 하이퍼마라메터 값이 units 값을 변경 시키며 실험을 진행하였을 때, 다음과 같이 accuracy가 변화하였다.\n",
    "    | units    | loss\t    | accuracy |\n",
    "    |:--------:|:----------:|:--------:|\n",
    "    | 16\t   | 0.370456\t| 0.852574 |\n",
    "    | 32\t   | 0.366094\t| 0.855483 |\n",
    "    | 64\t   | 0.371462\t| 0.856704 |\n",
    "    | 128\t   | 0.384762\t| 0.861139 |\n",
    "    | 256\t   | 0.510656\t| 0.858738 |\n",
    "- 프로젝트를 통하어 얻을 수 있었던 가장 높은 accuracy는 86%로 85% 이상을 달성하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nonprofit-detail",
   "metadata": {},
   "source": [
    "### 회고\n",
    "1. 이번 프로젝트에서 어려웠던 점\n",
    "    - 프로젝트를 진행하는 것에 있어서 자연어 처리를 처음 진행해 본다!-는 점 자체가 어려웠다. 자연어는 이전에 주로 다루었던 텍스트 데이터와 이미지 데이터와 다르게 인코딩을 거치고 나면 원본을 어떤 느낌이었는지 전혀 알아볼 수 없기 때문에 중간과정을 print하여 보아도 이게 잘 처리 되고 있는 것인지 판단하기가 어려워 진행에 난항을 겪었다. 다행히도 shape를 자주 찍어보면 이 점을 조금이나마 극복할 수 있다는 것을 중간에 깨달아 프로젝트 후반에는 데이터의 형태에 어영부영 적응할 수 있었다.\n",
    "    - 가장 큰 고비는 accuracy가 85% 이상을 가지 못하여 해매이던 때였다. 루브릭 평가의 기준으로부터 미루어봤을 때, 기존에 학습 된 임베딩을 모델로 들고왔을 경우, accuracy의 극적으로 변화할 것만 같았는데 실상은 전혀 그렇지 못하였다. 그런 이유로 임베딩을 추가로 2개 더 가져와 테스트를 진행하였지만 결과를 비슷하였다. 최종적으로 85%를 넘어 86%에 도달한 것은 하이퍼 파라미터를 보정하여 모델을 변화시켜 주었을 때였다. 모델을 성능을 올리려면 하나의 요소에 집착할 것이 아니라 전체적으로 살피고 변화를 주어야 한다는 점을 깨닫게 된 순간이었다.\n",
    "2. 프로젝트를 진행하면서 알아낸 점 혹은 아직 모호한 점\n",
    "    - 기존의 classification과 다르게 이번 프로젝트의 predict 값은 0 또는 1로 딱 나오는 것이 아니라 0과 1 사이의 실수값으로 도출된다! 85%의 늪에서 허우적거리고 있던 시절, accuary 말고 다른 평가 지표들도 확인해 보고 싶어서 predict를 실행해 보고 알게 된 사항이다. 추가로 train 과정에서 accuracy와 loss 뿐만 아니라 precision과 recall 값도 history로 얻을 수 있다는 점도 알게 되었다. 다만, 해당 수치들을 어떻게 연산하는지에 대한 의문이 아직 남아 있다. prediect의 결과가 딱 기존에 입력하는 target 값과 다른데, 그럼 이 값을 반올림을 하거나 하는 과정을 거치는 것인지 아직 찾아보지 못하였다.\n",
    "3. 자기 다짐\n",
    "    - 이번 프로젝트 aiffel 인생에 있어서 큰 다짐을 하게 되었다. going deeper 단계에서 절대 자연어 처리 과정으로 가지 않을 것이다.....절대.......... .... .. ..  ..  .     ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raising-argument",
   "metadata": {},
   "source": [
    "## Code Cellection\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handed-venezuela",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "random-score",
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel-dj1/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/aiffel-dj1/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/aiffel-dj1/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/aiffel-dj1/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/aiffel-dj1/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/aiffel-dj1/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/aiffel-dj1/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/aiffel-dj1/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/aiffel-dj1/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/aiffel-dj1/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/aiffel-dj1/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/aiffel-dj1/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import re\n",
    "\n",
    "from konlpy.tag import Okt\n",
    "from konlpy.tag import Mecab\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.initializers import Constant\n",
    "from collections import Counter\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "workspace_path = os.getenv('HOME')+'/workspace/aiffel-exploation-workspace/E04_sentiment_classification'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "missing-alberta",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### 데이터 로더 : `load_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "stable-newfoundland",
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def load_data(train_data, test_data, num_words=10000):\n",
    "    tokenizer = Mecab()\n",
    "    stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']\n",
    "\n",
    "    train_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "    train_data = train_data.dropna(how = 'any') \n",
    "    test_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "    test_data = test_data.dropna(how = 'any') \n",
    "\n",
    "    X_train = []\n",
    "    for sentence in train_data['document']:\n",
    "        temp_X = tokenizer.morphs(sentence) # 토큰화\n",
    "        temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "        X_train.append(temp_X)\n",
    "\n",
    "    X_test = []\n",
    "    for sentence in test_data['document']:\n",
    "        temp_X = tokenizer.morphs(sentence) # 토큰화\n",
    "        temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "        X_test.append(temp_X)\n",
    "\n",
    "    words = np.concatenate(X_train).tolist()\n",
    "    counter = Counter(words)\n",
    "    counter = counter.most_common(10000-4)\n",
    "    vocab = ['<PAD>', '<BOS>', '<UNK>', '<UNUSED>'] + [key for key, _ in counter]\n",
    "    word_to_index = {word:index for index, word in enumerate(vocab)}\n",
    "\n",
    "    def wordlist_to_indexlist(wordlist):\n",
    "        return [word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in wordlist]\n",
    "\n",
    "    X_train = list(map(wordlist_to_indexlist, X_train))\n",
    "    X_test = list(map(wordlist_to_indexlist, X_test))\n",
    "\n",
    "    return X_train, np.array(list(train_data['label'])), X_test, np.array(list(test_data['label'])), word_to_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confident-cemetery",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### `get_encoded_sentence`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "confident-receiver",
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 문장 1개를 활용할 딕셔너리와 함께 주면, 단어 인덱스 리스트 벡터로 변환해 주는 함수입니다. \n",
    "# 단, 모든 문장은 <BOS>로 시작하는 것으로 합니다. \n",
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index['<BOS>']]+[word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in sentence.split()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brave-detector",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### `get_encoded_sentences`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "japanese-briefing",
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 여러 개의 문장 리스트를 한꺼번에 단어 인덱스 리스트 벡터로 encode해 주는 함수입니다. \n",
    "def get_encoded_sentences(sentences, word_to_index):\n",
    "    return [get_encoded_sentence(sentence, word_to_index) for sentence in sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "related-manchester",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### `get_decoded_sentence`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ceramic-float",
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 숫자 벡터로 encode된 문장을 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    return ' '.join(index_to_word[index] if index in index_to_word else '<UNK>' for index in encoded_sentence[1:])  #[1:]를 통해 <BOS>를 제외"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excessive-access",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### `get_decoded_sentences`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "concerned-landscape",
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 여러개의 숫자 벡터로 encode된 문장을 한꺼번에 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentences(encoded_sentences, index_to_word):\n",
    "    return [get_decoded_sentence(encoded_sentence, index_to_word) for encoded_sentence in encoded_sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modular-bread",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### `add_padding`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "painful-civilization",
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def add_padding(data, padding, maxlen):\n",
    "    return keras.preprocessing.sequence.pad_sequences(data,\n",
    "                                                      value=word_to_index[\"<PAD>\"],\n",
    "                                                      padding=padding, \n",
    "                                                      maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "designing-chorus",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### `get_rnn_model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "vocational-exchange",
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_rnn_model(vocab_size, word_vector_dim, units, embedding_matrix=\"\"):\n",
    "    rnn_model = keras.Sequential()\n",
    "    if embedding_matrix == \"\":\n",
    "        rnn_model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "    else:\n",
    "        rnn_model.add(keras.layers.Embedding(vocab_size, \n",
    "                                             word_vector_dim, \n",
    "                                             embeddings_initializer=Constant(embedding_matrix),  # 카피한 임베딩을 여기서 활용\n",
    "                                             input_length=maxlen, \n",
    "                                             trainable=True))   # trainable을 True로 주면 Fine-tuning\n",
    "    rnn_model.add(keras.layers.LSTM(units))\n",
    "    rnn_model.add(keras.layers.Dense(units, activation='relu'))\n",
    "    rnn_model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    rnn_model.summary()\n",
    "    return rnn_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viral-thickness",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### `get_one_d_cnn_model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "contained-planet",
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_one_d_cnn_model(vocab_size, word_vector_dim, embedding_matrix=\"\"):\n",
    "    one_d_cnn_model = keras.Sequential()\n",
    "    \n",
    "    if embedding_matrix == \"\":\n",
    "        one_d_cnn_model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "    else:\n",
    "        one_d_cnn_model.add(keras.layers.Embedding(vocab_size, \n",
    "                                                   word_vector_dim, \n",
    "                                                   embeddings_initializer=Constant(embedding_matrix),  # 카피한 임베딩을 여기서 활용\n",
    "                                                   input_length=maxlen, \n",
    "                                                   trainable=True))   # trainable을 True로 주면 Fine-tuning\n",
    "    one_d_cnn_model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "    one_d_cnn_model.add(keras.layers.MaxPooling1D(5))\n",
    "    one_d_cnn_model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "    one_d_cnn_model.add(keras.layers.GlobalMaxPooling1D())\n",
    "    one_d_cnn_model.add(keras.layers.Dense(8, activation='relu'))\n",
    "    one_d_cnn_model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "    one_d_cnn_model.summary()\n",
    "    return one_d_cnn_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "voluntary-comfort",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### `get_one_d_one_l_cnn_model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "proud-brighton",
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_one_d_one_l_cnn_model(vocab_size, word_vector_dim, embedding_matrix=\"\"):\n",
    "    one_d_one_l_cnn_model = keras.Sequential()\n",
    "    if embedding_matrix == \"\":\n",
    "        one_d_one_l_cnn_model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "    else:\n",
    "        one_d_one_l_cnn_model.add(keras.layers.Embedding(vocab_size, \n",
    "                                                   word_vector_dim, \n",
    "                                                   embeddings_initializer=Constant(embedding_matrix),  # 카피한 임베딩을 여기서 활용\n",
    "                                                   input_length=maxlen, \n",
    "                                                   trainable=True))   # trainable을 True로 주면 Fine-tuning\n",
    "    one_d_one_l_cnn_model.add(keras.layers.GlobalMaxPooling1D())\n",
    "    one_d_one_l_cnn_model.add(keras.layers.Dense(8, activation='relu'))\n",
    "    one_d_one_l_cnn_model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "    one_d_one_l_cnn_model.summary()    \n",
    "    return one_d_one_l_cnn_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "independent-outreach",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### `train`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "recovered-fourth",
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def train(model, model_name, X_train, y_train, X_val, y_val, epochs):\n",
    "    # val_loss이 증가하면, 과적합 징후므로 val_loss이 4회 증가하면 학습을 조기 종료(Early Stopping)\n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
    "\n",
    "    print(\"start train {} ============================================== \".format(model_name))\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "              \n",
    "    history = model.fit(X_train, y_train,\n",
    "                        epochs=epochs,\n",
    "                        callbacks=[es],\n",
    "                        batch_size=512,\n",
    "                        validation_data=(X_val, y_val),\n",
    "                        verbose=2)\n",
    "    print(\"train completed ============================================== \".format(model_name))\n",
    "    return history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "typical-container",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### `get_history_plot`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "jewish-reliance",
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_sub_plot(history, targets, labels, fig, n, title, color):\n",
    "    x = range(1, len(history[targets[0]]) +1 )\n",
    "    plt = fig.add_subplot(1, 3, n)\n",
    "    plt.plot(x, history[targets[0]], color + 'o', label=labels[0])\n",
    "    plt.plot(x, history[targets[1]], color,  label=labels[1])\n",
    "    plt.set_xlabel('Epochs')\n",
    "    plt.set_ylabel('Loss')\n",
    "    plt.set_title(title)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "chief-english",
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def show_history_plot(histories, model_names):\n",
    "    targets = [['loss', 'val_loss'], ['acc', 'val_acc']]\n",
    "    labels = [['Training loss', 'Validation loss'], ['Training acc', 'Validation acc']]\n",
    "    titles = ['Training and validation loss','Training and validation accuracy']\n",
    "    colors = ['b', 'r']\n",
    "    \n",
    "    for i in range(2):\n",
    "        fig = plt.figure(figsize=(15, 5))\n",
    "        for j in range(len(histories)):\n",
    "            get_sub_plot(histories[j], targets[i], labels[i], fig, j+1, model_names[j], colors[i])\n",
    "        fig.suptitle(titles[i])\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outdoor-settle",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### `save_embedding_layer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "waiting-fiction",
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def save_embedding_layer(models, model_names):\n",
    "    for i in range(len(models)):\n",
    "        \n",
    "        path = workspace_path + '/data/suheeeee/' + model_names[i] + '.txt'\n",
    "        vectors = models[i].get_weights()[0]\n",
    "        \n",
    "        f = open(path, 'w')\n",
    "        f.write('{} {}\\n'.format(vocab_size-4, word_vector_dim))  # 몇개의 벡터를 얼마 사이즈로 기재할지 타이틀을 씁니다\n",
    "\n",
    "        # 단어 개수(에서 특수문자 4개는 제외하고)만큼의 워드 벡터를 파일에 기록합니다. \n",
    "        for i in range(4,vocab_size):\n",
    "            f.write('{} {}\\n'.format(index_to_word[i], ' '.join(map(str, vectors[i, :]))))\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exotic-martin",
   "metadata": {},
   "source": [
    "#### `test_word2vector`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "impressive-leather",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def test_word2vector(wv):\n",
    "    words = [\"재미\", \"지루\", \"아깝\", \"명작\", \"별로\", \"유치\", \"답답\"]\n",
    "\n",
    "    df = pd.DataFrame(columns=range(1,10))\n",
    "\n",
    "    for word in words:\n",
    "        if word in wv.vocab:\n",
    "            new_row = pd.DataFrame([pd.Series([res[0] for res in  wv.most_similar(word)])],\n",
    "                                    columns=df.columns, index=[word])\n",
    "            df = df.append(new_row)\n",
    "    \n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "related-corporation",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### `get_embedding_matrix`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "addressed-anatomy",
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_embedding_matrix(vocab_size, word_vector_dim, index_to_word, wv):\n",
    "    embedding_matrix = np.random.rand(vocab_size, word_vector_dim)\n",
    "\n",
    "    # embedding_matrix에 Word2Vpartial_y_trainec 워드벡터를 단어 하나씩마다 차례차례 카피한다.\n",
    "    for i in range(4,vocab_size):\n",
    "        if index_to_word[i] in wv:\n",
    "            embedding_matrix[i] = wv[index_to_word[i]]\n",
    "            \n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standing-valuation",
   "metadata": {},
   "source": [
    "## ref\n",
    "- [딥러닝을 이용한 자연어 처리 입문-영어/한국어 Word2Vec 실습](https://wikidocs.net/50739)\n",
    "- [딥 러닝을 이용한 자연어 처리 입문-RNN을 이용한 텍스트 분류](https://wikidocs.net/44249)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
